# ARCHS4 preprocessing

Load libraries
```{r}
library(bigstatsr)
library(data.table)
library(dplyr)
library(rsvd)
library(glmnet)
library(Matrix)
library(knitr)
library(here)
library(hdf5r)
library(biomaRt)
#library(EDASeq)
```

Output 

```{r}
output_nb_path <- here("output/vignettes/plier2_testing/archs4_full")
dir.create(output_nb_path, showWarnings = FALSE, recursive = TRUE)
```

Load the local files

```{r}
source(here("R/solvers.R"))
source(here("R/utilsNew.R"))
```

Download ARCHS4 

```{r download_archs4_if_needed, eval = TRUE, echo = TRUE, message = TRUE}
url <- "https://s3.dev.maayanlab.cloud/archs4/files/human_gene_v2.5.h5"
output_dir <- here::here("data", "archs4")
output_file <- file.path(output_dir, "human_gene_v2.5.h5")

if (!file.exists(output_file)) {
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  command <- sprintf("wget -c '%s' -O '%s'", url, output_file)
  tryCatch({
    system(command)
    cat("File downloaded successfully to:", output_file, "\n")
  }, error = function(e) {
    cat("Error during download:", e$message, "\n")
  })
} else {
  cat("File already exists. Skipping download.\n")
}
```

Read in ARCHS4 file 
```{r}
file_path <- here("data/archs4/human_gene_v2.5.h5")
h5        <- H5File$new(file_path, mode = "r")
dset      <- h5[["/data/expression"]]
gene_symbols <- h5[["/meta/genes/symbol"]]$read()
gene_ids     <- h5[["/meta/genes/ensembl_gene"]]$read()
sample_names <- h5[["/meta/samples/geo_accession"]]$read()
n_genes      <- length(gene_symbols)
n_samples    <- length(sample_names)
```

Get gene lengths for this Ensembl version

```{r}
#FIXME: this is only needed if we apply TPM normalization
#
# TODO: check, I'm not entirely sure if this is the best way to get gene
# lengths (using EDASeq, below, was giving an error)
output_file <- file.path(output_nb_path, "gene_lengths.rds")

if (!file.exists(output_file)) {
  ensembl_ver <- 107
  ensembl <- useEnsembl(biomart="ensembl", version=ensembl_ver)
  mart <- biomaRt::useDataset("hsapiens_gene_ensembl", ensembl)
  gene_info <- biomaRt::getBM(
    filters = "hgnc_symbol",
    attributes = c("ensembl_gene_id", "hgnc_symbol", "transcript_length"),
    values = gene_symbols, 
    mart = mart
  )

  gene_lengths <- gene_info %>%
    group_by(hgnc_symbol, ensembl_gene_id) %>%
    summarize(gene_length_bp = max(transcript_length, na.rm = TRUE)) %>%
    pull(gene_length_bp, name = hgnc_symbol)

  saveRDS(gene_lengths, file = output_file)
} else {
  gene_lengths <- readRDS(output_file)
  cat("File already exists. Skipping download.\n")
}


#if (!file.exists(output_file)) {
#  gene_lengths <- EDASeq::getGeneLengthAndGCContent(gene_ids, "hsa")
#  saveRDS(gene_lengths, file = output_file)
#} else {
#  gene_lengths <- readRDS(output_file)
#  cat("File already exists. Skipping download.\n")
#}
```

```{r}
# keep in data only genes for which we have lengths
gene_symbols_idx <- which( gene_symbols %in% names(gene_lengths) )
gene_symbols_thin <- gene_symbols[gene_symbols_idx]
gene_lengths <- gene_lengths[gene_symbols_thin]
n_genes_thin <- length(gene_symbols_thin)
```

Create FBM matrix

```{r}
fbm_file  <- file.path(output_nb_path, "FBMarchs4")
archs4FBM <- FBM(
  nrow        = n_genes_thin,
  ncol        = n_samples,
#  type        = "float",
  backingfile = fbm_file,
  create_bk   = TRUE
)
```

Populate it with data

```{r}
block_size <- 100
n_blocks   <- ceiling(n_samples / block_size)

pb <- txtProgressBar(min = 0, max = n_blocks, style = 3)

for (i in 1:n_blocks) {
  setTxtProgressBar(pb, i)

  start_row <- (i-1) * block_size + 1
  end_row <- min(i * block_size, n_samples)

  # FIXME: here I apply CPM normalization; it might not be the best approach,
  # but reading the h5 file by genes (instead of by samples) is very slow, and
  # this is needed for TPM/etc
  #raw_block <- t(cpm_norm(dset[start_row:end_row, ]))

  # tpm
  raw_block <- NULL
  tryCatch(
    expr = {
      raw_block <- dset[start_row:end_row, ]
    },
    error = function(e) {
      message(paste("Error with block: ", i))
    }
  )
  if (is.null(raw_block)) {
    # FIXME: the FBM file will have zero rows here
    raw_block <- matrix(1e-10, (end_row - start_row + 1), n_genes)
  }

  raw_block <- raw_block[, gene_symbols_idx]
  raw_block <- t(tpm_norm(raw_block, gene_lengths))
  #raw_block <- t(tpm_norm(dset[start_row:end_row, gene_symbols_idx], gene_lengths))

  archs4FBM[, start_row:end_row] <- as.matrix(raw_block)
}
```

Once done, close h5 file:

```{r}
h5$close_all()
```

```{r}
cleanFBM(archs4FBM)
```

```{r}
rowStats=computeRowStatsFBM(archs4FBM)
plot(rowStats$row_means, rowStats$row_variances, log="y")
```

Filter the data. Doing aggressive filtering to reduce the number of genes.

```{r}
filterResult=filterFBM(archs4FBM, rowStats,mean_cutoff = 1, var_cutoff = 0.1, backingfile =paste0(fbm_file, "_filtered")) 
archs4FBMfiltered=filterResult$fbm_filtered
gene_symbols_thin=gene_symbols_thin[filterResult$kept_rows]
rowStatsAll=rowStats
rowStats$row_means=rowStats$row_means[filterResult$kept_rows]
rowStats$row_variances=rowStats$row_variances[filterResult$kept_rows]
```

Do the z-scoring
```{r}
zscoreFBM(archs4FBMfiltered, rowStats = rowStats)
```

save the FBM object for quick loading
```{r}
archs4FBMfiltered$save()

meta <- list()
meta$rowNames <- gene_symbols_thin
meta$colNames <- sample_names
saveRDS(meta, paste0(fbm_file, "_meta.RDS"))
```

Precompute the SVD
```{r}
# number of samples 888821
# square root of 888821 = 942, using as a k
# square  root of 80000 = 282, using as a k

k = 942
archs4FBM.svd=big_randomSVD(archs4FBMfiltered, k = k)
```

Run simpleDecomp as the base model 
```{r}
decomp_file <- file.path(output_nb_path, "archs4SimpleDecompResult.RDS")

if (!file.exists(decomp_file)) {
  archs4.sdres <- simpleDecomp(archs4FBMfiltered, k = k, svdres = archs4FBM.svd)
  saveRDS(archs4.sdres, file = decomp_file)
} else {
  archs4.sdres <- readRDS(decomp_file)
}
```

Download some pathways
```{r}
gmtList=list()

gmtList[["Wiki"]]=getGMT("https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=WikiPathway_2021_Human")
gmtList[["MGI"]]=getGMT("https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=MGI_Mammalian_Phenotype_Level_4_2021")
gmtList[["GO"]]=getGMT("https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=GO_Biological_Process_2023")
gmtList[["Reactome"]]=getGMT("https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=Reactome_2022")
gmtList[["CellMarkers"]]=getGMT("https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=CellMarker_2024")
```

Create a pathMat object and save
```{r}
pathMat = gmtListToSparseMat(gmtList[c(5)])
#saveRDS(gmtList, "gmtList.RDS")
#saveRDS(pathMat, "pathMat.RDS")
```

Get a matched pathway set
The FBM version doesn't do any subsetting, everything has to match exactly
```{r}
matchedPaths=getMatchedPathwayMat(pathMat, meta$rowNames)
Chat=getChat(matchedPaths, method = "fast")
```

# Run PLIER2

Run PLIER2, setting `max.iter` low for demonstration
```{r}
archs4.plier2 <- PLIERv2(
  archs4FBMfiltered,
  matchedPaths,
  sdres = archs4.sdres,
  Chat = Chat,
  doCrossval = T,
  multiplier = 3,
  max.U.updates = 3,
  max.iter = 350,
  k = k,
)
```

```{r}
saveRDS(archs4.plier2, file = file.path(output_nb_path, "archs4_PLIER2.rds"))
```
